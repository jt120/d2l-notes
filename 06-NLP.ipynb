{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06-NLP.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPP+GkaaJdVTfE8UNTbGUkV"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1yiphlMFCHAq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3c8d17e3-3898-4e37-cb3b-24cfa9593c4a","executionInfo":{"status":"ok","timestamp":1582119282197,"user_tz":-480,"elapsed":917,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["import torch\n","from torch import nn\n","import numpy as np\n","import pandas as pd\n","import zipfile\n","from google.colab import files\n","from google.colab import drive\n","from pathlib import Path\n","from torch import nn, optim\n","import torch.nn.functional as F\n","import random\n","import time\n","import math\n","\n","torch.manual_seed(1)\n","np.set_printoptions(suppress=True)\n","\n","print(torch.__version__)\n","torch.set_default_tensor_type('torch.FloatTensor')"],"execution_count":52,"outputs":[{"output_type":"stream","text":["1.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lK_HpjIrp1UV","colab_type":"code","colab":{}},"source":["def sgd(params, lr, batch_size):\n","    # 为了和原书保持一致，这里除以了batch_size，但是应该是不用除的，因为一般用PyTorch计算loss时就默认已经\n","    # 沿batch维求了平均了。\n","    for param in params:\n","        param.data -= lr * param.grad / batch_size # 注意这里更改param时用的param.data\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv89lvFnm7sH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"756d5208-b331-416d-9feb-32ab350124ec","executionInfo":{"status":"ok","timestamp":1582118478887,"user_tz":-480,"elapsed":25490,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["drive.mount('/content/drive')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hUfEDsoHnHr0","colab_type":"code","colab":{}},"source":["data_dir = Path('/content/drive/My Drive/d2l/data')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t8P2m1pfkzxs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"078531a7-43ec-4be5-9238-8609a2db0e28","executionInfo":{"status":"ok","timestamp":1582117897170,"user_tz":-480,"elapsed":676,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(torch.__version__)\n","print(device)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["1.4.0\n","cpu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bOo_BkFGkgST","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"3d309c61-a738-4e3d-da55-5b0b280bece9","executionInfo":{"status":"ok","timestamp":1582117869961,"user_tz":-480,"elapsed":1532,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["\n","X, W_xh = torch.randn(3, 1), torch.randn(1, 4)\n","H, W_hh = torch.randn(3, 4), torch.randn(4, 4)\n","torch.matmul(X, W_xh) + torch.matmul(H, W_hh)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.1138, -0.5415, -0.2195, -2.1594],\n","        [-2.3756,  0.3845, -0.5473, -2.1300],\n","        [-0.5901, -1.6954,  0.1111,  0.1095]])"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"CjweLqk2ksgk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"b2e46549-89df-412f-ed85-55054a0512bb","executionInfo":{"status":"ok","timestamp":1582117873379,"user_tz":-480,"elapsed":828,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["torch.matmul(torch.cat((X, H), dim=1), torch.cat((W_xh, W_hh), dim=0))\n"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.1138, -0.5415, -0.2195, -2.1594],\n","        [-2.3756,  0.3845, -0.5473, -2.1300],\n","        [-0.5901, -1.6954,  0.1111,  0.1095]])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"acYHFECrkuNi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c56f6355-6389-4341-932d-e11ace058eb8","executionInfo":{"status":"ok","timestamp":1582118742621,"user_tz":-480,"elapsed":1311,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["with zipfile.ZipFile(data_dir / 'jaychou_lyrics.txt.zip') as zin:\n","    with zin.open('jaychou_lyrics.txt') as f:\n","        corpus_chars = f.read().decode('utf-8')\n","corpus_chars[:40]"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'想要有直升机\\n想要和你飞到宇宙去\\n想要和你融化在一起\\n融化在宇宙里\\n我每天每天每'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"z6OTLNKgocdS","colab_type":"code","colab":{}},"source":["def load_data_jay_lyrics():\n","    \"\"\"加载周杰伦歌词数据集\"\"\"\n","    with zipfile.ZipFile(data_dir / 'jaychou_lyrics.txt.zip') as zin:\n","        with zin.open('jaychou_lyrics.txt') as f:\n","            corpus_chars = f.read().decode('utf-8')\n","    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n","    corpus_chars = corpus_chars[0:10000]\n","    idx_to_char = list(set(corpus_chars))\n","    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n","    vocab_size = len(char_to_idx)\n","    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n","    return corpus_indices, char_to_idx, idx_to_char, vocab_size"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"spXPqITfmnnq","colab_type":"code","colab":{}},"source":["(corpus_indices, char_to_idx, idx_to_char, vocab_size) = load_data_jay_lyrics()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OpjFAKiVof_C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"147e0959-21d3-4fe6-ea7a-a8ba28f69de3","executionInfo":{"status":"ok","timestamp":1582118901196,"user_tz":-480,"elapsed":1005,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["\n","def one_hot(x, n_class, dtype=torch.float32): \n","    # X shape: (batch), output shape: (batch, n_class)\n","    x = x.long()\n","    res = torch.zeros(x.shape[0], n_class, dtype=dtype, device=x.device)\n","    res.scatter_(1, x.view(-1, 1), 1)\n","    return res\n","    \n","x = torch.tensor([0, 2])\n","x = one_hot(x, vocab_size)\n","print(x.shape, x)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["torch.Size([2, 1027]) tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 1.,  ..., 0., 0., 0.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1yulMRmlojHh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"79513e89-fc6c-4e77-e998-30ab3dbc4685","executionInfo":{"status":"ok","timestamp":1582118917621,"user_tz":-480,"elapsed":783,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["def to_onehot(X, n_class):  \n","    # X shape: (batch, seq_len), output: seq_len elements of (batch, n_class)\n","    return [one_hot(X[:, i], n_class) for i in range(X.shape[1])]\n","\n","X = torch.arange(10).view(2, 5)\n","inputs = to_onehot(X, vocab_size)\n","print(len(inputs), inputs[0].shape)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["5 torch.Size([2, 1027])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P3P6qRMLotKY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"703081b5-d5e1-449a-f0a2-4e767606ff79","executionInfo":{"status":"ok","timestamp":1582118957571,"user_tz":-480,"elapsed":849,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n","print('will use', device)\n","\n","def get_params():\n","    def _one(shape):\n","        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)\n","        return torch.nn.Parameter(ts, requires_grad=True)\n","\n","    # 隐藏层参数\n","    W_xh = _one((num_inputs, num_hiddens))\n","    W_hh = _one((num_hiddens, num_hiddens))\n","    b_h = torch.nn.Parameter(torch.zeros(num_hiddens, device=device, requires_grad=True))\n","    # 输出层参数\n","    W_hq = _one((num_hiddens, num_outputs))\n","    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, requires_grad=True))\n","    return nn.ParameterList([W_xh, W_hh, b_h, W_hq, b_q])\n","\n","def init_rnn_state(batch_size, num_hiddens, device):\n","    return (torch.zeros((batch_size, num_hiddens), device=device), )\n","\n","def rnn(inputs, state, params):\n","    # inputs和outputs皆为num_steps个形状为(batch_size, vocab_size)的矩阵\n","    W_xh, W_hh, b_h, W_hq, b_q = params\n","    H, = state\n","    outputs = []\n","    for X in inputs:\n","        H = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(H, W_hh) + b_h)\n","        Y = torch.matmul(H, W_hq) + b_q\n","        outputs.append(Y)\n","    return outputs, (H,)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["will use cpu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nZ1AyKIwoybS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"80e0a3d7-82d6-496e-cc07-4a9e6e4395a3","executionInfo":{"status":"ok","timestamp":1582118966382,"user_tz":-480,"elapsed":881,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["state = init_rnn_state(X.shape[0], num_hiddens, device)\n","inputs = to_onehot(X.to(device), vocab_size)\n","params = get_params()\n","outputs, state_new = rnn(inputs, state, params)\n","print(len(outputs), outputs[0].shape, state_new[0].shape)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["5 torch.Size([2, 1027]) torch.Size([2, 256])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Knjjcsmoo47x","colab_type":"code","colab":{}},"source":["def predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,\n","                num_hiddens, vocab_size, device, idx_to_char, char_to_idx):\n","    state = init_rnn_state(1, num_hiddens, device)\n","    output = [char_to_idx[prefix[0]]]\n","    for t in range(num_chars + len(prefix) - 1):\n","        # 将上一时间步的输出作为当前时间步的输入\n","        X = to_onehot(torch.tensor([[output[-1]]], device=device), vocab_size)\n","        # 计算输出和更新隐藏状态\n","        (Y, state) = rnn(X, state, params)\n","        # 下一个时间步的输入是prefix里的字符或者当前的最佳预测字符\n","        if t < len(prefix) - 1:\n","            output.append(char_to_idx[prefix[t + 1]])\n","        else:\n","            output.append(int(Y[0].argmax(dim=1).item()))\n","    return ''.join([idx_to_char[i] for i in output])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxOlC-Hko7Dq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"df6077b3-6cf5-4820-dc4d-b21e9b4e3f86","executionInfo":{"status":"ok","timestamp":1582118991923,"user_tz":-480,"elapsed":804,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["predict_rnn('分开', 4, rnn, params, init_rnn_state, num_hiddens, vocab_size,\n","            device, idx_to_char, char_to_idx)"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'分开蝴夜听家'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"-RQzmJ6io9Fr","colab_type":"code","colab":{}},"source":["def grad_clipping(params, theta, device):\n","    norm = torch.tensor([0.0], device=device)\n","    for param in params:\n","        norm += (param.grad.data ** 2).sum()\n","    norm = norm.sqrt().item()\n","    if norm > theta:\n","        for param in params:\n","            param.grad.data *= (theta / norm)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GA7h1dvSpcJJ","colab_type":"code","colab":{}},"source":["# 本函数已保存在d2lzh_pytorch包中方便以后使用\n","def data_iter_random(corpus_indices, batch_size, num_steps, device=None):\n","    # 减1是因为输出的索引x是相应输入的索引y加1\n","    num_examples = (len(corpus_indices) - 1) // num_steps\n","    epoch_size = num_examples // batch_size\n","    example_indices = list(range(num_examples))\n","    random.shuffle(example_indices)\n","\n","    # 返回从pos开始的长为num_steps的序列\n","    def _data(pos):\n","        return corpus_indices[pos: pos + num_steps]\n","    if device is None:\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    \n","    for i in range(epoch_size):\n","        # 每次读取batch_size个随机样本\n","        i = i * batch_size\n","        batch_indices = example_indices[i: i + batch_size]\n","        X = [_data(j * num_steps) for j in batch_indices]\n","        Y = [_data(j * num_steps + 1) for j in batch_indices]\n","        yield torch.tensor(X, dtype=torch.float32, device=device), torch.tensor(Y, dtype=torch.float32, device=device)\n","\n","\n","# 本函数已保存在d2lzh_pytorch包中方便以后使用\n","def data_iter_consecutive(corpus_indices, batch_size, num_steps, device=None):\n","    if device is None:\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    corpus_indices = torch.tensor(corpus_indices, dtype=torch.float32, device=device)\n","    data_len = len(corpus_indices)\n","    batch_len = data_len // batch_size\n","    indices = corpus_indices[0: batch_size*batch_len].view(batch_size, batch_len)\n","    epoch_size = (batch_len - 1) // num_steps\n","    for i in range(epoch_size):\n","        i = i * num_steps\n","        X = indices[:, i: i + num_steps]\n","        Y = indices[:, i + 1: i + num_steps + 1]\n","        yield X, Y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aX7284K5pd44","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"e63d3001-a3f3-4192-8934-f939dbccb94f","executionInfo":{"status":"ok","timestamp":1582119135686,"user_tz":-480,"elapsed":809,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["my_seq = list(range(30))\n","for X, Y in data_iter_random(my_seq, batch_size=2, num_steps=6):\n","    print('X: ', X, '\\nY:', Y, '\\n')"],"execution_count":41,"outputs":[{"output_type":"stream","text":["X:  tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n","        [18., 19., 20., 21., 22., 23.]]) \n","Y: tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n","        [19., 20., 21., 22., 23., 24.]]) \n","\n","X:  tensor([[12., 13., 14., 15., 16., 17.],\n","        [ 6.,  7.,  8.,  9., 10., 11.]]) \n","Y: tensor([[13., 14., 15., 16., 17., 18.],\n","        [ 7.,  8.,  9., 10., 11., 12.]]) \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7hHGXWFBpmPi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"fbded2a2-298c-4f04-a99b-a51121ab3ddd","executionInfo":{"status":"ok","timestamp":1582119152106,"user_tz":-480,"elapsed":780,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["for X, Y in data_iter_consecutive(my_seq, batch_size=2, num_steps=6):\n","    print('X: ', X, '\\nY:', Y, '\\n')"],"execution_count":43,"outputs":[{"output_type":"stream","text":["X:  tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n","        [15., 16., 17., 18., 19., 20.]]) \n","Y: tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n","        [16., 17., 18., 19., 20., 21.]]) \n","\n","X:  tensor([[ 6.,  7.,  8.,  9., 10., 11.],\n","        [21., 22., 23., 24., 25., 26.]]) \n","Y: tensor([[ 7.,  8.,  9., 10., 11., 12.],\n","        [22., 23., 24., 25., 26., 27.]]) \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nQTp3Q_opJkw","colab_type":"code","colab":{}},"source":["def train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n","                          vocab_size, device, corpus_indices, idx_to_char,\n","                          char_to_idx, is_random_iter, num_epochs, num_steps,\n","                          lr, clipping_theta, batch_size, pred_period,\n","                          pred_len, prefixes):\n","    if is_random_iter:\n","        data_iter_fn = data_iter_random\n","    else:\n","        data_iter_fn = data_iter_consecutive\n","    params = get_params()\n","    loss = nn.CrossEntropyLoss()\n","\n","    for epoch in range(num_epochs):\n","        if not is_random_iter:  # 如使用相邻采样，在epoch开始时初始化隐藏状态\n","            state = init_rnn_state(batch_size, num_hiddens, device)\n","        l_sum, n, start = 0.0, 0, time.time()\n","        data_iter = data_iter_fn(corpus_indices, batch_size, num_steps, device)\n","        for X, Y in data_iter:\n","            if is_random_iter:  # 如使用随机采样，在每个小批量更新前初始化隐藏状态\n","                state = init_rnn_state(batch_size, num_hiddens, device)\n","            else:  # 否则需要使用detach函数从计算图分离隐藏状态\n","                for s in state:\n","                    s.detach_()\n","            \n","            inputs = to_onehot(X, vocab_size)\n","            # outputs有num_steps个形状为(batch_size, vocab_size)的矩阵\n","            (outputs, state) = rnn(inputs, state, params)\n","            # 拼接之后形状为(num_steps * batch_size, vocab_size)\n","            outputs = torch.cat(outputs, dim=0)\n","            # Y的形状是(batch_size, num_steps)，转置后再变成长度为\n","            # batch * num_steps 的向量，这样跟输出的行一一对应\n","            y = torch.transpose(Y, 0, 1).contiguous().view(-1)\n","            # 使用交叉熵损失计算平均分类误差\n","            l = loss(outputs, y.long())\n","            \n","            # 梯度清0\n","            if params[0].grad is not None:\n","                for param in params:\n","                    param.grad.data.zero_()\n","            l.backward()\n","            grad_clipping(params, clipping_theta, device)  # 裁剪梯度\n","            sgd(params, lr, 1)  # 因为误差已经取过均值，梯度不用再做平均\n","            l_sum += l.item() * y.shape[0]\n","            n += y.shape[0]\n","\n","        if (epoch + 1) % pred_period == 0:\n","            print('epoch %d, perplexity %f, time %.2f sec' % (\n","                epoch + 1, math.exp(l_sum / n), time.time() - start))\n","            for prefix in prefixes:\n","                print(' -', predict_rnn(prefix, pred_len, rnn, params, init_rnn_state,\n","                    num_hiddens, vocab_size, device, idx_to_char, char_to_idx))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F1OlxaFjpLTi","colab_type":"code","colab":{}},"source":["num_epochs, num_steps, batch_size, lr, clipping_theta = 250, 35, 32, 1e2, 1e-2\n","pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nru52i2SpNuw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"5c26b24a-a791-4736-f389-fff271ba3548","executionInfo":{"status":"ok","timestamp":1582119537520,"user_tz":-480,"elapsed":252598,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n","                      vocab_size, device, corpus_indices, idx_to_char,\n","                      char_to_idx, True, num_epochs, num_steps, lr,\n","                      clipping_theta, batch_size, pred_period, pred_len,\n","                      prefixes)"],"execution_count":53,"outputs":[{"output_type":"stream","text":["epoch 50, perplexity 69.169166, time 1.00 sec\n"," - 分开 我想要这想你 我不要这想你 我不要这想你 我不要这想你 我不要这想你 我不要这想你 我不要这想你 \n"," - 不分开 我不要再想你 我不要这想你 我不要这想你 我不要这想你 我不要这想你 我不要这想你 我不要这想你 \n","epoch 100, perplexity 9.865890, time 1.02 sec\n"," - 分开 一直在它留 谁话的美前 你的完美主义 太什么 的手段人我 娘你的爹蜜时光 我现 再有你血后的公老 \n"," - 不分开吗 我将你 你爱我 我想就这样牵着你的手不放开 爱可不能够永远单纯没有悲  我 靠带你的肩车 我 想\n","epoch 150, perplexity 2.784900, time 1.00 sec\n"," - 分开 一只两剧三 我让它事抽离 如在我遇见你是一场悲剧 我可以的生写就样元  是在伊斯 有颗种发  你在\n"," - 不分开吗 我将你的 你在西元 我想多有我出大 从小就耳濡目染 什么刀枪南棍棒 我都耍的有模有样 什么兵器最\n","epoch 200, perplexity 1.573320, time 1.00 sec\n"," - 分开 一只心它拳仪的母斑鸠 印括安老斑鸠 腿短毛不多 除非是乌鸦抢了它的窝 它在灌木丛旁邂逅 一只令它心\n"," - 不分开扫 我叫你爸 你打我妈 这样不吗 怎这没纵 你一止 痛一句珍重 也有苦衷 不候内 我想了声生活 我变\n","epoch 250, perplexity 1.297193, time 0.99 sec\n"," - 分开 一只用著三 谁在它停留的 为什么我女朋友场外加油 你却还让我出糗 从小就耳一直到老什想找对 我爱还\n"," - 不分开吗 我叫你爸 你打我妈 这样对吗干嘛这样 何必让酒牵鼻子走 瞎 说笑什打我听妈 却是你的不状 默经跟\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SeqCAX-YqnJw","colab_type":"text"},"source":["# pytorch"]},{"cell_type":"code","metadata":{"id":"koAIehYtpPd2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6c1976dc-16f0-42c7-bab5-be421b151802","executionInfo":{"status":"ok","timestamp":1582119572291,"user_tz":-480,"elapsed":1186,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["num_hiddens = 256\n","# rnn_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens) # 已测试\n","rnn_layer = nn.RNN(input_size=vocab_size, hidden_size=num_hiddens)\n","\n","num_steps = 35\n","batch_size = 2\n","state = None\n","X = torch.rand(num_steps, batch_size, vocab_size)\n","Y, state_new = rnn_layer(X, state)\n","print(Y.shape, len(state_new), state_new[0].shape)\n","\n","class RNNModel(nn.Module):\n","    def __init__(self, rnn_layer, vocab_size):\n","        super(RNNModel, self).__init__()\n","        self.rnn = rnn_layer\n","        self.hidden_size = rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1) \n","        self.vocab_size = vocab_size\n","        self.dense = nn.Linear(self.hidden_size, vocab_size)\n","        self.state = None\n","\n","    def forward(self, inputs, state): # inputs: (batch, seq_len)\n","        # 获取one-hot向量表示\n","        X = to_onehot(inputs, vocab_size) # X是个list\n","        Y, self.state = self.rnn(torch.stack(X), state)\n","        # 全连接层会首先将Y的形状变成(num_steps * batch_size, num_hiddens)，它的输出\n","        # 形状为(num_steps * batch_size, vocab_size)\n","        output = self.dense(Y.view(-1, Y.shape[-1]))\n","        return output, self.state\n","\n","def predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,\n","                      char_to_idx):\n","    state = None\n","    output = [char_to_idx[prefix[0]]] # output会记录prefix加上输出\n","    for t in range(num_chars + len(prefix) - 1):\n","        X = torch.tensor([output[-1]], device=device).view(1, 1)\n","        if state is not None:\n","            if isinstance(state, tuple): # LSTM, state:(h, c)  \n","                state = (state[0].to(device), state[1].to(device))\n","            else:   \n","                state = state.to(device)\n","            \n","        (Y, state) = model(X, state)  # 前向计算不需要传入模型参数\n","        if t < len(prefix) - 1:\n","            output.append(char_to_idx[prefix[t + 1]])\n","        else:\n","            output.append(int(Y.argmax(dim=1).item()))\n","    return ''.join([idx_to_char[i] for i in output])"],"execution_count":56,"outputs":[{"output_type":"stream","text":["torch.Size([35, 2, 256]) 1 torch.Size([2, 256])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OCOcGCggqwLN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0d26e7aa-e376-4456-84b9-ba9c6e01ced2","executionInfo":{"status":"ok","timestamp":1582119572292,"user_tz":-480,"elapsed":647,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["model = RNNModel(rnn_layer, vocab_size).to(device)\n","predict_rnn_pytorch('分开', 10, model, vocab_size, device, idx_to_char, char_to_idx)"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'分开补鹿否鹿堂鹿连鹿否芜'"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"7TvS6FDvqyEG","colab_type":"code","colab":{}},"source":["def train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n","                                corpus_indices, idx_to_char, char_to_idx,\n","                                num_epochs, num_steps, lr, clipping_theta,\n","                                batch_size, pred_period, pred_len, prefixes):\n","    loss = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    model.to(device)\n","    state = None\n","    for epoch in range(num_epochs):\n","        l_sum, n, start = 0.0, 0, time.time()\n","        data_iter = data_iter_consecutive(corpus_indices, batch_size, num_steps, device) # 相邻采样\n","        for X, Y in data_iter:\n","            if state is not None:\n","                # 使用detach函数从计算图分离隐藏状态, 这是为了\n","                # 使模型参数的梯度计算只依赖一次迭代读取的小批量序列(防止梯度计算开销太大)\n","                if isinstance (state, tuple): # LSTM, state:(h, c)  \n","                    state = (state[0].detach(), state[1].detach())\n","                else:   \n","                    state = state.detach()\n","    \n","            (output, state) = model(X, state) # output: 形状为(num_steps * batch_size, vocab_size)\n","            \n","            # Y的形状是(batch_size, num_steps)，转置后再变成长度为\n","            # batch * num_steps 的向量，这样跟输出的行一一对应\n","            y = torch.transpose(Y, 0, 1).contiguous().view(-1)\n","            l = loss(output, y.long())\n","            \n","            optimizer.zero_grad()\n","            l.backward()\n","            # 梯度裁剪\n","            grad_clipping(model.parameters(), clipping_theta, device)\n","            optimizer.step()\n","            l_sum += l.item() * y.shape[0]\n","            n += y.shape[0]\n","        \n","        try:\n","            perplexity = math.exp(l_sum / n)\n","        except OverflowError:\n","            perplexity = float('inf')\n","        if (epoch + 1) % pred_period == 0:\n","            print('epoch %d, perplexity %f, time %.2f sec' % (\n","                epoch + 1, perplexity, time.time() - start))\n","            for prefix in prefixes:\n","                print(' -', predict_rnn_pytorch(\n","                    prefix, pred_len, model, vocab_size, device, idx_to_char,\n","                    char_to_idx))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYn3oBjaqzss","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"6b65d4d1-e34b-4e93-95d4-f9c834472e6d","executionInfo":{"status":"ok","timestamp":1582119795499,"user_tz":-480,"elapsed":486,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}}},"source":["num_epochs, batch_size, lr, clipping_theta = 250, 32, 1e-3, 1e-2 # 注意这里的学习率设置\n","pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n","train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n","                            corpus_indices, idx_to_char, char_to_idx,\n","                            num_epochs, num_steps, lr, clipping_theta,\n","                            batch_size, pred_period, pred_len, prefixes)"],"execution_count":59,"outputs":[{"output_type":"stream","text":["epoch 50, perplexity 8.582886, time 0.70 sec\n"," - 分开始我可 不想 你不我 想要你 一场悲  你在那里很 还学上心涌失控 快使用双截棍 哼哼哈兮 快使用双\n"," - 不分开始的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让\n","epoch 100, perplexity 1.246632, time 0.70 sec\n"," - 分开 我可以 我想要和你你眼我 你 一直了我 就是开不了口让她知道 我一定会呵护著你 也逗你笑 你对我 \n"," - 不分开不了我不著我不能我不 我不能再想你我不 我不 我不要 不知我觉 我已了这节奏 后知后觉 又过了一个秋\n","epoch 150, perplexity 1.069866, time 0.70 sec\n"," - 分开 你在人运  想要你却只会听的汉堡 我想要你的微笑每天都能看到  我知道这里很美但家乡的你更美原来我\n"," - 不分开不了我不要再想 我不要再对 我不能再想 我不能我不 我不 我不要再想了我不能我不 我不 我不要再想你\n","epoch 200, perplexity 1.033585, time 0.70 sec\n"," - 分开 你在人  我想要你这只会痛 周杰伦河  就是开不了口让她知道 就是那怕大你睡家 一个人 后知后觉 \n"," - 不分开不 我不要再想是我不 我不了 不要再想 你叫我我不带你你 我不要再想你 爱情来的太快就像龙卷风 离不\n","epoch 250, perplexity 1.021751, time 0.69 sec\n"," - 分开 你在人  我想要你这里我不妈妈通 温暖  爱就来了太快地的让我面 像可爱像 妈妈 难道你没有你有多\n"," - 不分开不 我不要再想是你不的我不被 爱情走的太快就像龙卷风 不能承受我已无处可躲 我不要再想 我不要再想 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YQqUkUEmrSRU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}