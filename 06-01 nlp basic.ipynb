{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06-01 nlp basic.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN88hNXLMvetm7UI7cDkt8N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f41772567f4b41c6aaef4efb3249bf29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d327ca971c1b447885dcca591c8ab578","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9e1632775fa94d1ca4b71f39c2fb36c2","IPY_MODEL_63e45a4c923c4b63b6b28223d9efb8ae"]}},"d327ca971c1b447885dcca591c8ab578":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e1632775fa94d1ca4b71f39c2fb36c2":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f7679278ca2f4efc8c716547fb58abb3","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd6e8bbfb39d4514a2cfaff0b91c2f37"}},"63e45a4c923c4b63b6b28223d9efb8ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_410b2b33855c4768906f9483b4203755","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 232k/232k [00:00&lt;00:00, 3.46MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46baed89c3474ea696a8e6a9fe43afd5"}},"f7679278ca2f4efc8c716547fb58abb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dd6e8bbfb39d4514a2cfaff0b91c2f37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"410b2b33855c4768906f9483b4203755":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46baed89c3474ea696a8e6a9fe43afd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"zACykn0H5tVB","colab_type":"code","outputId":"99b1424f-972d-490a-942e-db7718b944f6","executionInfo":{"status":"ok","timestamp":1581607557681,"user_tz":-480,"elapsed":599,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# !pip install transformers > /dev/null\n","\n","import torch\n","from torch import nn\n","import numpy as np\n","import collections\n","torch.manual_seed(1)\n","\n","from transformers import BertTokenizer\n","\n","print(torch.__version__)\n","torch.set_default_tensor_type('torch.FloatTensor')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.4.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t1JY7Jw-GoGc","colab_type":"text"},"source":["# 文本的表示\n","\n","人可以理解象形文字，计算机只能理解二进制。表达问题的步骤有\n","\n","1. 分词\n","2. 映射\n","\n","映射有各种方式，例如\n","1. 词袋模型\n","2. tf-idf\n","3. word2vec\n","4. bert"]},{"cell_type":"code","metadata":{"id":"YwrB6VhGJpCl","colab_type":"code","colab":{}},"source":["class Vocab(object):\n","    def __init__(self, tokens, min_freq=0, use_special_tokens=False):\n","        counter = count_corpus(tokens)\n","        self.token_freq = list(counter.items())\n","        self.idx_to_token = []\n","        if use_special_tokens:\n","            self.pad, self.bos, self.eos, self.unk = (0,1,2,3)\n","            self.idx_to_token += ['</s>','<s>','</s>','<unk>']\n","        else:\n","            self.unk = 0\n","            self.idx_to_token += ['<unk>']\n","        self.idx_to_token += [token for token, freq in self.token_freq if freq >= min_freq and token not in self.idx_to_token]\n","        self.token_to_idx = dict()\n","        for idx, token in enumerate(self.idx_to_token):\n","            self.token_to_idx[token] = idx\n","        \n","\n","    def __len__(self):\n","        return len(self.idx_to_token)\n","\n","    def __getitem__(self, tokens):\n","        if not isinstance(tokens, (list, tuple)):\n","            return self.token_to_idx.get(tokens, self.unk)\n","        return [self.__getitem__(token) for token in tokens]\n","\n","    def to_tokens(self, indices):\n","        if not isinstance(indices, (list, tuple)):\n","            return self.idx_to_token[indices]\n","        return [self.idx_to_token[index] for index in indices]\n","        \n","def count_corpus(sentences):\n","    tokens = [tk for st in sentences for tk in st]\n","    return collections.Counter(tokens)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hZ_Df_yBLqgw","colab_type":"code","colab":{}},"source":["voc = Vocab(tokens)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UAMeRVy1LzKf","colab_type":"code","outputId":"5f7ebe50-5359-4f5c-b0e1-c9cbaf52948e","executionInfo":{"status":"ok","timestamp":1581608075749,"user_tz":-480,"elapsed":856,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["voc.to_tokens(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'('"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"4R2WIpAo-DnX","colab_type":"code","colab":{}},"source":["txt = \"\"\"\n","The Time Traveller (for so it will be convenient to speak of him) was expounding a recondite matter to us. His pale grey eyes shone and twinkled, and his usually pale face was flushed and animated. The fire burnt brightly, and the soft radiance of the incandescent lights in the lilies of silver caught the bubbles that flashed and passed in our glasses. Our chairs, being his patents, embraced and caressed us rather than submitted to be sat upon, and there was that luxurious after-dinner atmosphere, when thought runs gracefully free of the trammels of precision. And he put it to us in this way—marking the points with a lean forefinger—as we sat and lazily admired his earnestness over this new paradox (as we thought it) and his fecundity.\n","“You must follow me carefully. I shall have to controvert one or two ideas that are almost universally accepted. The geometry, for instance, they taught you at school is founded on a misconception.”\n","“Is not that rather a large thing to expect us to begin upon?” said Filby, an argumentative person with red hair.\n","“I do not mean to ask you to accept anything without reasonable ground for it. You will soon admit as much as I need from you. You know of course that a mathematical line, a line of thickness nil, has no real existence. They taught you that? Neither has a mathematical plane. These things are mere abstractions.”\n","\"\"\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GdRLIZzHarm","colab_type":"code","colab":{}},"source":["lines = txt.split(\"\\n\")[1:-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vu0l8WVfHiOd","colab_type":"code","outputId":"a05c870d-3206-4a58-92f3-7c9f8ad8cc66","executionInfo":{"status":"ok","timestamp":1581606946949,"user_tz":-480,"elapsed":783,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(lines)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"ZuZeN1MDHi6d","colab_type":"code","outputId":"b337cd6b-a4cc-4b58-bec6-f27d420debc8","executionInfo":{"status":"ok","timestamp":1581606949716,"user_tz":-480,"elapsed":781,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["lines[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The Time Traveller (for so it will be convenient to speak of him) was expounding a recondite matter to us. His pale grey eyes shone and twinkled, and his usually pale face was flushed and animated. The fire burnt brightly, and the soft radiance of the incandescent lights in the lilies of silver caught the bubbles that flashed and passed in our glasses. Our chairs, being his patents, embraced and caressed us rather than submitted to be sat upon, and there was that luxurious after-dinner atmosphere, when thought runs gracefully free of the trammels of precision. And he put it to us in this way—marking the points with a lean forefinger—as we sat and lazily admired his earnestness over this new paradox (as we thought it) and his fecundity.'"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"ck20SeAoHkyY","colab_type":"code","colab":{}},"source":["tokens = lines[0].split(' ')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXMqC42LHyuN","colab_type":"code","outputId":"53da6244-65cc-466e-f5d5-3efc98ffd968","executionInfo":{"status":"ok","timestamp":1581606977520,"user_tz":-480,"elapsed":554,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(tokens[:10])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['The', 'Time', 'Traveller', '(for', 'so', 'it', 'will', 'be', 'convenient', 'to']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1z-8mXsuHz19","colab_type":"code","colab":{}},"source":["import spacy\n","nlp = spacy.load('en_core_web_sm')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0wU6bhrIEd4","colab_type":"code","outputId":"2dce70ed-4d25-4123-f3c8-8fb1858e4ee9","executionInfo":{"status":"ok","timestamp":1581607099244,"user_tz":-480,"elapsed":772,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["s = \"Mr. Chen doesn't agree with my suggestion.\"\n","\n","doc = nlp(s)\n","print([t.text for t in doc])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['Mr.', 'Chen', 'does', \"n't\", 'agree', 'with', 'my', 'suggestion', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3xMTI830IHll","colab_type":"code","outputId":"97616d9d-5fce-46a4-a5a6-5f323aefb77d","executionInfo":{"status":"ok","timestamp":1581607196127,"user_tz":-480,"elapsed":1120,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["f41772567f4b41c6aaef4efb3249bf29","d327ca971c1b447885dcca591c8ab578","9e1632775fa94d1ca4b71f39c2fb36c2","63e45a4c923c4b63b6b28223d9efb8ae","f7679278ca2f4efc8c716547fb58abb3","dd6e8bbfb39d4514a2cfaff0b91c2f37","410b2b33855c4768906f9483b4203755","46baed89c3474ea696a8e6a9fe43afd5"]}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f41772567f4b41c6aaef4efb3249bf29","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mujZ2f16IpEV","colab_type":"code","outputId":"a342efbb-c200-4515-c5c7-763247c41e12","executionInfo":{"status":"ok","timestamp":1581607209799,"user_tz":-480,"elapsed":927,"user":{"displayName":"Liu Ze","photoUrl":"","userId":"02617697151426951757"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(tokenizer.tokenize(s))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['mr', '.', 'chen', 'doesn', \"'\", 't', 'agree', 'with', 'my', 'suggestion', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NK4EAExRIsZu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4IRE-uHIMLrU","colab_type":"text"},"source":["# 语言模型\n","\n","词之间都是相关联的，也就是根据context，可以预测mask，根据当前的句子，可以预测下一个句子\n","\n","## n元语法\n","\n","当前词的出现，只和前面n个词相关，n阶马尔科夫链\n","\n","1元语法 unigram\n","2元语法 bigram 2个词\n","3元语法 trigram\n","\n","一个长度为4的序列，上述3种表述为\n","\n","$\\begin{aligned}\n","P(w_1, w_2, w_3, w_4) &=  P(w_1) P(w_2) P(w_3) P(w_4) ,\\\\\n","P(w_1, w_2, w_3, w_4) &=  P(w_1) P(w_2 \\mid w_1) P(w_3 \\mid w_2) P(w_4 \\mid w_3) ,\\\\\n","P(w_1, w_2, w_3, w_4) &=  P(w_1) P(w_2 \\mid w_1) P(w_3 \\mid w_1, w_2) P(w_4 \\mid w_2, w_3) .\n","\\end{aligned}$\n","\n","n小不准确，n大复杂度大"]},{"cell_type":"code","metadata":{"id":"oXlfGkuyNwNp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}